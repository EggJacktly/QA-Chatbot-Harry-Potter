{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b43019e",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "| Version | Date     | Creator          | Change description                               |\n",
    "|---------|----------|------------------|--------------------------------------------------|\n",
    "| v0.01   | 03/09/23 | Jaikishan Khatri | Loader, Splitter, Storage, Retreival, Generation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50642346",
   "metadata": {},
   "source": [
    "# QA Chatbot for parsing Harry Potter books to generate answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b615d72",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "The pipeline for converting raw unstructured data into a QA chain looks like this:\n",
    "\n",
    "1. <b>Loading</b>: First we need to load our data. Unstructured data can be loaded from many sources. Use the LangChain integration hub to browse the full set of loaders. Each loader returns data as a LangChain Document.\n",
    "2. <b>Splitting</b>: Text splitters break Documents into splits of specified size\n",
    "3. <b>Storage</b>: Storage (e.g., often a vectorstore) will house and often embed the splits\n",
    "4. <b>Retrieval</b>: The app retrieves splits from storage (e.g., often with similar embeddings to the input question)\n",
    "5. <b>Generation</b>: An LLM produces an answer using a prompt that includes the question and the retrieved data\n",
    "6. <b>Conversation</b> (Extension): Hold a multi-turn conversation by adding Memory to your QA chain.\n",
    "\n",
    "![LLM-QA-flowchart.jpeg](https://python.langchain.com/assets/images/qa_flow-9fbd91de9282eb806bda1c6db501ecec.jpeg)\n",
    "\n",
    "Image source: [LangChain](https://python.langchain.com/assets/images/qa_flow-9fbd91de9282eb806bda1c6db501ecec.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f09abe",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efed97b9",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "! pip install -qq -U langchain tiktoken pypdf faiss-gpu\n",
    "! pip install -qq -U transformers InstructorEmbedding sentence_transformers\n",
    "! pip install -qq -U accelerate bitsandbytes xformers einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d02d8d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be907da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# text splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# retreivers\n",
    "from langchain.retrievers import SVMRetriever\n",
    "\n",
    "# prompts\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# vector stores\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# models\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc85ec",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "For manipulable variables in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e8ac1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # LLMs\n",
    "    model_name = 'Photolens-llama-2-7b' # wizardlm, bloom, falcon, llama2-7b, llama2-13b, 'Photolens-llama-2-7b'\n",
    "    temperature = 0,\n",
    "    top_p = 0.95,\n",
    "    repetition_penalty = 1.15    \n",
    "    \n",
    "    # splitting\n",
    "    split_chunk_size = 1000\n",
    "    split_overlap = 0\n",
    "    \n",
    "    # embeddings\n",
    "    embeddings_model_repo = 'sentence-transformers/all-MiniLM-L6-v2' # 'sentence-transformers/all-MiniLM-L6-v2', \n",
    "    # 'sentence-transformers/multi-qa-MiniLM-L6-cos-v1', GPT4AllEmbeddings()\n",
    "    \n",
    "    retriever_type = 'similarity_search' # 'similarity_search', 'MultiQueryRetriever', 'Max marginal relevance', 'SVMRetriever'\n",
    "    \n",
    "    # similar passages\n",
    "    k = 5\n",
    "    \n",
    "    # quantization config\n",
    "#     quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)\n",
    "    \n",
    "    # paths\n",
    "    PDFs_path = './Data/HP books/'\n",
    "    Embeddings_path =  './faiss-hp-sentence-transformers/'\n",
    "    Persist_directory = './harry-potter-vectorstore/' \n",
    "    offload_folder = './offload_folder/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae6f28",
   "metadata": {},
   "source": [
    "### Step 1: Loader \n",
    "using PyPDFLoader\n",
    "\n",
    "Load PDF using `pypdf and chunks at character level.\\\n",
    "Loader also stores page numbers in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a337672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                   | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|████████████████████████▍                                                                                                                                                  | 1/7 [00:11<01:08, 11.44s/it]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▊                                                                                                                          | 2/7 [00:12<00:41,  8.33s/it]\u001b[A\n",
      " 43%|█████████████████████████████████████████████████████████████████████████▎                                                                                                 | 3/7 [00:15<00:26,  6.62s/it]\u001b[A\n",
      " 57%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                         | 4/7 [00:29<00:26,  8.94s/it]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 5/7 [00:30<00:13,  6.67s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 6/7 [00:31<00:04,  4.82s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:33<00:00,  4.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.2 s, sys: 1.3 s, total: 33.5 s\n",
      "Wall time: 33.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    CFG.PDFs_path,\n",
    "    glob=\"./*.pdf\",\n",
    "    loader_cls=PyPDFLoader,\n",
    "    show_progress=True,\n",
    "    use_multithreading=True\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58cb1b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4114"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7aa2b",
   "metadata": {},
   "source": [
    "### Step 2: Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15214f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8383"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = CFG.split_chunk_size,\n",
    "    chunk_overlap  = CFG.split_overlap,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd75346",
   "metadata": {},
   "source": [
    "### Step 3: Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0aa711c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(embeddings_model_repo: str, Embeddings_path: str = './faiss_index_hp', new_vectorstore: bool=False):\n",
    "    \n",
    "    if new_vectorstore == True:\n",
    "        \n",
    "        if embeddings_model_repo.startswith('sentence-transformers'):\n",
    "            embeddings = HuggingFaceInstructEmbeddings(model_name = embeddings_model_repo,\n",
    "                                                       model_kwargs = {\"device\": \"cuda\"})\n",
    "\n",
    "        elif embeddings_model_repo.startswith('GPT4All'):\n",
    "            embeddings = HuggingFaceInstructEmbeddings(model_name = embeddings_model_repo,\n",
    "                                                       model_kwargs = {\"device\": \"cuda\"})\n",
    "\n",
    "        ### create embeddings and new_vectorstore\n",
    "        vectorstore = FAISS.from_documents(documents = all_splits, \n",
    "                                           embedding = embeddings)\n",
    "\n",
    "        ### persist vector database\n",
    "        vectorstore.save_local(\"faiss_index_hp\")\n",
    "        \n",
    "    else:\n",
    "\n",
    "        ### download embeddings model\n",
    "        embeddings = HuggingFaceInstructEmbeddings(model_name = CFG.embeddings_model_repo,\n",
    "                                                   model_kwargs = {\"device\": \"cuda\"})\n",
    "\n",
    "        ### load vectorstore embeddings\n",
    "        vectorstore = FAISS.load_local(CFG.Embeddings_path, embeddings)\n",
    "        \n",
    "    return vectorstore, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embeddings(CFG.embeddings_model_repo, CFG.Embeddings_path, new_vectorstore=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fcb8110",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "### download embeddings model\n",
    "if CFG.embeddings_model_repo.startswith('sentence-transformers'):\n",
    "    embeddings = HuggingFaceInstructEmbeddings(\n",
    "        model_name = CFG.embeddings_model_repo,\n",
    "        model_kwargs = {\"device\": \"cuda\"}\n",
    "    )\n",
    "    \n",
    "elif CFG.embeddings_model_repo.startswith('GPT4All'):\n",
    "    embeddings = HuggingFaceInstructEmbeddings(\n",
    "        model_name = CFG.embeddings_model_repo,\n",
    "        model_kwargs = {\"device\": \"cuda\"}\n",
    "    )\n",
    "    \n",
    "### create embeddings and DB\n",
    "vectorstore = FAISS.from_documents(documents = all_splits, embedding = embeddings)\n",
    "\n",
    "### persist vector database\n",
    "vectorstore.save_local(\"faiss_index_hp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "45cac591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are Hagrid's favourite animals?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e29787",
   "metadata": {},
   "source": [
    "### Step 4. Retrieve\n",
    "similarity_search\\\n",
    "MultiQueryRetriever\\\n",
    "Max marginal relevance\\\n",
    "SVMRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a84c10",
   "metadata": {},
   "source": [
    "### Promt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0420cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Don't try to make up an answer, if you don't know just say that you don't know.\n",
    "Answer in the same language the question was asked. \n",
    "Use only the following pieces of context to answer the question at the end.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9010f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs = {\"k\": CFG.k, \"search_type\" : \"similarity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e29704f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x7f60d2bf7100>, search_type='similarity', search_kwargs={'k': 5, 'search_type': 'similarity'})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(retriever_type: str = 'similarity_search', k: int = 4, question: str, vectorstore, all_splits, embeddings):\n",
    "    \n",
    "    # searches for similarity among the retreived documents\n",
    "    if retriever_type == 'similarity_search':\n",
    "        retriever = vectorstore.as_retriever(search_kwargs = {'k': k, 'search_type' : 'similarity'})\n",
    "    \n",
    "    # selects for relevance and diversity among the retrieved documents\n",
    "    elif retriever_type == 'Max marginal relevance':\n",
    "        retriever = vectorstore.as_retriever(search_kwargs = {'k': k, 'search_type' : 'MMR'})\n",
    "        \n",
    "    elif retriever_type == 'SVMRetriever':\n",
    "        svm_retriever = SVMRetriever.from_documents(all_splits, embeddings)\n",
    "        retriever_docs = svm_retriever.get_relevant_documents(question)\n",
    "        \n",
    "    # generates variants of the input question to improve retrieval using llm\n",
    "#     elif retriever_type == 'MultiQueryRetriever':\n",
    "#         retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectordb.as_retriever(), llm=llm)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Incorrect Retriever Type')\n",
    "        \n",
    "    return retriever_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f0cb4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_retriever = SVMRetriever.from_documents(all_splits, embeddings)\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "len(docs_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65bb42cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='breeding creatures he has dubbed “Blast-Ended \\nSkrewts,” highly dangerous crosses between manti-\\ncores and fire-crabs. The creation of new breeds of magical creature is, of course, an activity usually \\nclosely observed by the Department for the Regu-\\nlation and Control of Magical Creatures. Hagrid, however, considers himself to be above such petty \\nrestrictions.', metadata={'source': 'Data/HP books/Harry Potter - Book 4 - The Goblet of Fire.pdf', 'page': 453, 'start_index': 992}),\n",
       " Document(page_content='brate, does not present much of a ch allenge; the mouse, as a mammal,', metadata={'source': 'Data/HP books/Harry Potter - Book 5 - The Order of the Phoenix.pdf', 'page': 335, 'start_index': 1932}),\n",
       " Document(page_content='“But\\tthere\\taren’t\\twild\\tdragons\\tin\\tBritain?”\\tsaid\\tHarry.\\n\\t\\t\\t\\t\\t\\t“Of\\tcourse\\tthere\\tare,”\\tsaid\\tRon.\\t“Common\\tWelsh\\tGreen\\tand\\tHebridean\\nBlacks.\\tThe\\tMinistry\\tof\\tMagic\\thas\\ta\\tjob\\thushing\\tthem\\tup,\\tI\\tcan\\ttell\\tyou.\\tOur\\nkind\\thave\\tto\\tkeep\\tputting\\tspells\\ton\\tMuggles\\twho’ve\\tspotted\\tthem,\\tto\\tmake\\tthem\\nforget.”\\n\\t\\t\\t\\t\\t\\t“So\\twhat\\ton\\tearth’s\\tHagrid\\tup\\tto?”\\tsaid\\tHermione.', metadata={'source': 'Data/HP books/Harry Potter - Book 1 - The Sorcerers Stone.pdf', 'page': 166, 'start_index': 1964}),\n",
       " Document(page_content='mountain ranges. If his antics during Care of Mag-\\nical Creatures lessons are any guide, however, Frid-\\nwulfa’s son appears to have inherited her brutal nature. \\nIn a bizarre twist, Hagrid is reputed to have \\ndeveloped a close friend ship with the boy who \\nbrought around You-Know-Who’s fall from \\npower — thereby driving Hagrid’s own mother,', metadata={'source': 'Data/HP books/Harry Potter - Book 4 - The Goblet of Fire.pdf', 'page': 454, 'start_index': 988})]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3cf5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore.similarity_search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a850e72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='“But\\tthere\\taren’t\\twild\\tdragons\\tin\\tBritain?”\\tsaid\\tHarry.\\n\\t\\t\\t\\t\\t\\t“Of\\tcourse\\tthere\\tare,”\\tsaid\\tRon.\\t“Common\\tWelsh\\tGreen\\tand\\tHebridean\\nBlacks.\\tThe\\tMinistry\\tof\\tMagic\\thas\\ta\\tjob\\thushing\\tthem\\tup,\\tI\\tcan\\ttell\\tyou.\\tOur\\nkind\\thave\\tto\\tkeep\\tputting\\tspells\\ton\\tMuggles\\twho’ve\\tspotted\\tthem,\\tto\\tmake\\tthem\\nforget.”\\n\\t\\t\\t\\t\\t\\t“So\\twhat\\ton\\tearth’s\\tHagrid\\tup\\tto?”\\tsaid\\tHermione.', metadata={'source': 'Data/HP books/Harry Potter - Book 1 - The Sorcerers Stone.pdf', 'page': 166, 'start_index': 1964}),\n",
       " Document(page_content='Passersby\\tstared\\ta\\tlot\\tat\\tHagrid\\tas\\tthey\\twalked\\tthrough\\tthe\\tlittle\\ttown\\tto\\nthe\\tstation.\\tHarry\\tcouldn’t\\tblame\\tthem.\\tNot\\tonly\\twas\\tHagrid\\ttwice\\tas\\ttall\\tas\\nanyone\\telse,\\the\\tkept\\tpointing\\tat\\tperfectly\\tordinary\\tthings\\tlike\\tparking\\tmeters\\tand\\nsaying\\tloudly,\\t“See\\tthat,\\tHarry?\\tThings\\tthese\\tMuggles\\tdream\\tup,\\teh?”\\n\\t\\t\\t\\t\\t\\t“Hagrid,”\\tsaid\\tHarry,\\tpanting\\ta\\tbit\\tas\\the\\tran\\tto\\tkeep\\tup,\\t“did\\tyou\\tsay\\nthere\\tare\\tdragons\\tat\\tGringotts?”\\n\\t\\t\\t\\t\\t\\t“Well,\\tso\\tthey\\tsay,”\\tsaid\\tHagrid.\\t“Crikey,\\tI’d\\tlike\\ta\\tdragon.”', metadata={'source': 'Data/HP books/Harry Potter - Book 1 - The Sorcerers Stone.pdf', 'page': 49, 'start_index': 1902}),\n",
       " Document(page_content='had ever seen. They had the bodies, hind legs, and tails of horses, butthe front legs, wings, and heads of what seemed to be giant eagles, withcruel, steel-colored beaks and large, brilliantly, orange eyes. Thetalons on their front legs were half a foot long and deadly looking.Each of the beasts had a thick leather collar around its neck, which wasattached to a long chain, and the ends of all of these were held in thevast hands of Hagrid, who came jogging into the paddock behind thecreatures.\\n\"Gee up, there!\" he roared, shaking the chains and urging the creatures\\ntoward the fence where the class stood. Everyone drew back slightly asHagrid reached them and tethered the creatures to the fence.\\n\"Hippogriffs!\" Hagrid roared happily, waving a hand at them. \"Beau\\'iful,\\naren\\' they?\"\\nHarry could sort of see what Hagrid meant. Once you got over the first', metadata={'source': 'Data/HP books/Harry Potter - Book 3 - The Prisoner of Azkaban.pdf', 'page': 91, 'start_index': 736}),\n",
       " Document(page_content='“They won’ grow inter nuthin’,” said Hagrid. “I got ’em \\nter feed ter Aragog.” \\nAnd without warning, he burst into tears. \\n“Hagrid!” cried Hermione, leaping up, hurrying \\naround the table the long way to avoid the barrel of \\nmaggots, and putting an arm around his shaking \\nshoulders. “What is it?”', metadata={'source': 'Data/HP books/Harry Potter - Book 6 - The Half-Blood Prince.pdf', 'page': 256, 'start_index': 994})]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30237a82",
   "metadata": {},
   "source": [
    "### Step 5: Generate\n",
    "Retriever chain for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed74555",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever, \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
