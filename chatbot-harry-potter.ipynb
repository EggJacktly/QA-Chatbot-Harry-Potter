{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93c9eec",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "| Version | Date     | Creator          | Change description                                 |\n",
    "|---------|----------|------------------|----------------------------------------------------|\n",
    "| v0.07   | 10/09/23 | Jaikishan Khatri | Documentation update, Spanish language integration |\n",
    "| v0.06   | 08/09/23 | Jaikishan Khatri | Model performance and public release of repo       |\n",
    "| v0.05   | 07/09/23 | Jaikishan Khatri | Model comparison and tuning for better outputs     |\n",
    "| v0.04   | 06/09/23 | Jaikishan Khatri | Memory integration for chat functionality          |\n",
    "| v0.03   | 05/09/23 | Jaikishan Khatri | Trial of different embedding models                |\n",
    "| v0.02   | 04/09/23 | Jaikishan Khatri | Generation with diff local LLM models              |\n",
    "| v0.01   | 03/09/23 | Jaikishan Khatri | Loader, Splitter, Storage, Retrieval, Generation   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417593b4",
   "metadata": {},
   "source": [
    "# QA Chatbot for parsing Harry Potter books to generate answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b615d72",
   "metadata": {},
   "source": [
    "## Process  \n",
    "\n",
    "Here are a few methods you may use to limit an AI to only providing answers based on a particular dataset:  \n",
    "- **Retrieval-based**: Create a data indexing and searching information retrieval system that solely searches your dataset for solutions. To find answers, the chatbot would ask this search engine questions. Still, the chatbot itself might be a standard conversational paradigm. This system is also known as a multi-agent system.  \n",
    "- **Fine-tuning**: Use your dataset to fine-tune a large language model that is already available, such as [Llama 2](https://ai.meta.com/llama/). By doing this, you can customize the model while keeping its basic conversational capabilities.  \n",
    "- **Modular approach**: Use a generic conversational model for interpreting natural language and a different module that asks questions of your knowledge base to produce answers. The parts are kept apart as a result. This method is also known as the MOE (Mixture of Experts).\n",
    "- **Conversational scoping**: Whatever the primary method implementation, there should probably be some conversational scoping techniques, such as permitting only specific topics, rerouting questions that are off-topic back to the domain, responding \"I don't know\" when they are not relevant, etc.  \n",
    "\n",
    "The following notebook focuses on the Retrieval-based model using [LangChain] and [HuggingFace](https://huggingface.co/) models.\n",
    "\n",
    "According to ðŸ¦œðŸ”—*LangChain*, process for transforming unstructured raw data into a QA chain is as follows:\n",
    "\n",
    "1. **Loading**: We must load our data first. Numerous sources can be used to load unstructured data.\n",
    "2. **Splitting**: Documents are divided into splits of a predetermined size using text splitters. \n",
    "3. **Storage**: The splits will be stored and frequently embedded in storage (such as a vectorstore).\n",
    "4. **Retrieval**: The app fetches splits from storage (for instance, frequently with embeddings similar to the input query).\n",
    "5. **Generation**: An LLM generates a response using a prompt that contains the query and the data that was retrieved. \n",
    "6. **Conversation** (Extension): Adds Memory to the QA chain to hold a multi-turn dialogue.\n",
    "\n",
    "![LLM-QA-flowchart.jpeg](https://python.langchain.com/assets/images/qa_flow-9fbd91de9282eb806bda1c6db501ecec.jpeg)\n",
    "\n",
    "Image source: [LangChain](https://python.langchain.com/assets/images/qa_flow-9fbd91de9282eb806bda1c6db501ecec.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d119f6",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Install dependencies from requirements.txt and make sure GPU is available through CuDNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2a0205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T10:55:22.194815Z",
     "start_time": "2023-09-10T10:55:22.178794500Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0c709",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c565952",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-10T18:30:58.408037900Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 01:14:36.325879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 01:14:36.415226: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-11 01:14:36.824536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-11 01:14:36.824608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-11 01:14:36.824613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cabc118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:37.688388700Z",
     "start_time": "2023-09-08T06:29:37.676455500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following code runs on CUDA and CuDNN\n",
    "# Check if GPU is available\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcc679",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Major Hyperparameters which can be used to tune the output of LLMs:  \n",
    "- `temperature` is a hyperparameter that controls the randomness of language model output.  \n",
    "- `top_p` also known as nucleus sampling, is another hyperparameter that controls the randomness of language model output. It sets a threshold probability and selects the top tokens whose cumulative probability exceeds the threshold. The model then randomly samples from this set of tokens to generate output.  \n",
    "- `max_length` maximum token length.\n",
    "- `repetition_penalty` The penalty to apply to repeated tokens.\n",
    "- `chunk_size` is a hyperparameter for embeddings model which changes the size of chunks created by splitting.\n",
    "- `chunk_overlap` is another hyperparameter for embeddings model to have overlap between two chunks, this in turn helps in reducing data loss because of low semantic chunks created by the splitter.\n",
    "- `k` is the number of document chunks to feed the LLM model as context after extracting from the retriever.\n",
    "- `search_type` there are majorly three types of vectorstore retrievers: similarity, max marginal reference and similarity score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abb5337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:39.633202800Z",
     "start_time": "2023-09-08T06:29:39.589065Z"
    }
   },
   "outputs": [],
   "source": [
    "# working available models\n",
    "available_models = {'vicuna': 'lmsys/vicuna-7b-v1.3',\n",
    "                    'wizardlm': 'TheBloke/wizardLM-7B-HF',\n",
    "                    'Photolens-llama-2-7b': 'Photolens/llama-2-7b-langchain-chat',\n",
    "                    'llama2-7b': 'daryl149/llama-2-7b-chat-hf',\n",
    "                    'bloom': 'bigscience/bloom-7b1',\n",
    "                    'falcon': 'h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2',\n",
    "                    'Llama2-7b-es': 'clibrain/Llama-2-7b-ft-instruct-es-gptq-4bit'\n",
    "                   }\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    # Model name\n",
    "    # other working models in this program currently include: wizardlm, bloom, falcon, llama2-7b, Photolens-llama-2-7b, vicuna, \n",
    "    model_name = 'vicuna'\n",
    "    \n",
    "    # using temperature 0.0 or 0.1 because we don't want the LLM to go out of context\n",
    "    temperature = 0.1\n",
    "    \n",
    "    # using 0.95 to keep relevancy\n",
    "    top_p = 0.95 \n",
    "    \n",
    "    # use 1 for no penalty (higher the number higher the penalty)\n",
    "    repetition_penalty = 1 \n",
    "    \n",
    "    # document splitting\n",
    "    split_chunk_size = 500\n",
    "    split_overlap = 100\n",
    "    \n",
    "    # vector-based retriever search type\n",
    "    # 'similarity', 'mmr', 'similarity_score_threshold' (requires search_kwargs={\"score_threshold\": .5})\n",
    "    search_type = 'similarity' \n",
    "    \n",
    "    # create a new vectorstore, False for using pre-built vectorstore, always True after changing embeddings parameters\n",
    "    new_vectorstore = True\n",
    "    \n",
    "    # number of extracted passages using retriever\n",
    "    k = 4\n",
    "    \n",
    "    # quantization config\n",
    "#     quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)\n",
    "    \n",
    "    # paths\n",
    "    offload_folder = './offload_folder/'\n",
    "    csv_path = './model_comparison/'\n",
    "    \n",
    "    # select language to select model parameters\n",
    "    model_language = 'English' # 'English', 'Spanish'\n",
    "    \n",
    "    if model_language == 'English':\n",
    "        \n",
    "        # embeddings (larger models take up more RAM)\n",
    "        embeddings_model_repo = 'sentence-transformers/all-MiniLM-L12-v2'\n",
    "        \n",
    "        # path of vectorstore\n",
    "        embeddings_path =  './data/vectorstore-en'\n",
    "        \n",
    "        # path of pdf books in English\n",
    "        pdfs_path = './data/hp-books-en/'\n",
    "        \n",
    "    elif model_language == 'Spanish':\n",
    "        \n",
    "        # embeddings (larger models take up more RAM)\n",
    "        embeddings_model_repo = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "        \n",
    "        # path of vectorstore\n",
    "        embeddings_path =  './data/vectorstore-es'\n",
    "        \n",
    "        # path of pdf books in Spanish\n",
    "        pdfs_path = './data/hp-books-es/'\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Language can only be \"English\" or \"Spanish\"')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2b85713",
   "metadata": {},
   "source": [
    "### Tested English major embedding models\n",
    "# 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "# 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# 'sentence-transformers/all-MiniLM-L12-v2'\n",
    "# BAAI/bge-large-en\n",
    "\n",
    "### Tested Spanish/multilingual embedding models\n",
    "# sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "# intfloat/multilingual-e5-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24665c51",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "- There are many ways to load models using APIs from different LLM providers like Paid: [ChatOpenAI](https://openai.com/product) and Free: [HuggingFaceHub](https://huggingface.co/inference-api), etc. \n",
    "Models can also be loaded locally through [PrivateGPT](https://github.com/imartinez/privateGPT), [llama.cpp](https://github.com/ggerganov/llama.cpp), [GPT4ALL](https://github.com/nomic-ai/gpt4all).  \n",
    "\n",
    "- Currently, I'm using `HuggingFacePipeline` to load models locally which are hosted at [HuggingFace](https://huggingface.co/) because of good free resources available locally to me. \n",
    "\n",
    "- The file might not run in Colab due to limited free resources provided for free by Google. Required resources: 32 GB RAM, 8 GB dedicated GPU or Parallel GPUs with HuggingFace accelerate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af422c3a",
   "metadata": {},
   "source": [
    "### Load HuggingFace models locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdea2181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:41.297354300Z",
     "start_time": "2023-09-08T06:29:41.255386800Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(av_models, model_name = CFG.model_name):\n",
    "    \n",
    "    \"\"\" Returns the tokenizer and model for the specified model name.\n",
    "    Models are currently selected based on the ability to run on local machine with 32 GB Memory and 8 GB Cuda RAM to run.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : str\n",
    "        Name of the model to be used.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    tokenizer : transformers.tokenization_utils_base.PreTrainedTokenizerBase\n",
    "        Tokenizer for the specified model.\n",
    "    model : transformers.modeling_utils.PreTrainedModel\n",
    "        Model for the specified model.\n",
    "    max_len : int\n",
    "        Maximum length of the input sequence for the specified model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name == 'vicuna':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        max_length = 4096    \n",
    "        \n",
    "    elif model_name == 'wizardlm':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        \n",
    "        max_length = 4096  \n",
    "        \n",
    "        \n",
    "    elif model_name == 'Photolens-llama-2-7b':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        max_length = 4096\n",
    "        \n",
    "    elif model_name == 'llama2-7b':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        max_length = 4096\n",
    "\n",
    "    elif model_name == 'bloom':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "        )\n",
    "        \n",
    "        max_length = 4096\n",
    "\n",
    "    elif model_name == 'falcon':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        max_length = 4096\n",
    "    \n",
    "    elif model_name == 'Llama2-7b-es':\n",
    "        model_repo = av_models[model_name]\n",
    "        model_tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "        model_name = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "#             load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        max_length = 4096\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Incorrect Model Name')\n",
    "\n",
    "    return model_tokenizer, model_name, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8a3858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:55.480368100Z",
     "start_time": "2023-09-08T06:29:42.429420100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-26T19:52:47.324087Z",
     "iopub.status.busy": "2023-08-26T19:52:47.323715Z",
     "iopub.status.idle": "2023-08-26T19:58:04.634613Z",
     "shell.execute_reply": "2023-08-26T19:58:04.633514Z",
     "shell.execute_reply.started": "2023-08-26T19:52:47.32406Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6626b558b0143588a39f59790bebd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.85 s, sys: 4.88 s, total: 9.73 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer, model, max_len = create_model(available_models, model_name=CFG.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d48e0",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Create a pipeline for the model using `HuggingFacePipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ae9e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:55.480368100Z",
     "start_time": "2023-09-08T06:29:55.471351800Z"
    }
   },
   "outputs": [],
   "source": [
    "### Comment this cell if you want to run GPT4ALL models locally\n",
    "\n",
    "pipe = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    pad_token_id = tokenizer.eos_token_id,\n",
    "    max_length = max_len,\n",
    "    temperature = CFG.temperature,\n",
    "    top_p = CFG.top_p,\n",
    "    repetition_penalty = CFG.repetition_penalty\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c1dd2",
   "metadata": {},
   "source": [
    "### Load GPT4ALL models locally\n",
    "\n",
    "- To run GPT4ALL models locally, python library `gpt4all` should be installed. Currently, GPT4ALL models run on CPU only.\n",
    "- GPT4ALL models need the `.bin` files in the directory `./models/`, which can either be downloaded from the [model explorer](https://gpt4all.io/index.html) on the website or directly using parameter `allow_download=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69de187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Uncomment to run GPT4ALL models (Comment the Pipeline from HuggingFace)\n",
    "\n",
    "# from langchain.llms import GPT4All\n",
    "\n",
    "# llm = GPT4All(model='./models/ggml-gpt4all-j-v1.3-groovy', \n",
    "#               allow_download=True, \n",
    "#               temp=CFG.temperature\n",
    "#               top_p=CFG.top_p\n",
    "#               repeat_penalty=CFG.repetition_penalty,\n",
    "#               max_tokens=4096, \n",
    "#               n_threads = 12)\n",
    "\n",
    "# ### Tested models on this notebook\n",
    "# # nous-hermes-13b.ggmlv3.q4_0\n",
    "# # GPT4All-13B-snoozy.ggmlv3.q4_0\n",
    "# # ggml-gpt4all-j-v1.3-groovy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266c7a8",
   "metadata": {},
   "source": [
    "#### Print the model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1c7e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:55.510375900Z",
     "start_time": "2023-09-08T06:29:55.474350500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7efcf7ef0d90>, model_id='gpt2', model_kwargs=None, pipeline_kwargs=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2080d20",
   "metadata": {},
   "source": [
    "## QA Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b076785",
   "metadata": {},
   "source": [
    "### Step 1: Loading\n",
    "\n",
    "- Load data (here Harry Potter PDF books) and parse data from a directory and convert them into text.  \n",
    "- Using `DirectoryLoader` to load the directory of the PDF documents.  \n",
    "- Benefits of using `PyPDFLoader` is that it creates chunks at character level and also stores page numbers in metadata which can be used to reference the source files.\n",
    "- Loading can be done by multiple ways as mentioned in the [LangChain Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders.html) section.\n",
    "\n",
    "**Note:**\n",
    "The LangChain integration portal currently has [157 Document Loaders](https://integrations.langchain.com/). Each loader produces a LangChain Document as the data output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a337672c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:55.510375900Z",
     "start_time": "2023-09-08T06:29:55.489346100Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_raw_pdf(pdfs_path):\n",
    "    \n",
    "    \"\"\" Loads PDF documents from a directory and converts them into text.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    pdfs_path : str\n",
    "        Path to the directory containing PDF documents.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    documents : list\n",
    "        List of LangChain Documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    loader = DirectoryLoader(\n",
    "        pdfs_path,\n",
    "        loader_cls=PyPDFLoader,\n",
    "        glob=\"./*.pdf\",\n",
    "        show_progress=True,\n",
    "        use_multithreading=True\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e39fba",
   "metadata": {},
   "source": [
    "### Step 2: Splitter\n",
    "\n",
    "- Split the text up into small, semantically meaningful chunks (often sentences) of predefined sizes. This helps in creating smaller batches of data to be embedded in VectorStore. \n",
    "- These semantically related pieces of text are stored closer to each other for better extraction.\n",
    "- Benefit of using `RecursiveCharacterTextSplitter` is that it splits text by recursively looking at characters. Recursively tries to split by different characters to find one that works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15214f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:55.511355500Z",
     "start_time": "2023-09-08T06:29:55.499260800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_document_chunks(documents, split_chunk_size: int=500, split_overlap: int=0):\n",
    "    \n",
    "    \"\"\" Splits the documents into chunks of predefined size.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    documents : list\n",
    "        List of LangChain Documents.\n",
    "    split_chunk_size : int\n",
    "        Size of the chunks to be created from the documents.\n",
    "    split_overlap : int\n",
    "        Overlap between two chunks.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    doc_chunks : list\n",
    "        List of LangChain Documents.   \n",
    "    \"\"\"\n",
    "        \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=split_chunk_size,\n",
    "        chunk_overlap=split_overlap,\n",
    "        separators = [\"\\n\\n\", \"\\n\", \"\\t\", \" \", \"\"],\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    doc_chunks = text_splitter.split_documents(documents)\n",
    "    return doc_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8191322",
   "metadata": {},
   "source": [
    "### Step 3: Store\n",
    "\n",
    "- Embedding models are used to embedded sentences (Performance Sentence Embeddings) and to embedded search queries & paragraphs (Performance Semantic Search).  \n",
    "- The current embedding model was selected from the list of best [pre-trained sentence transformers](https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models) which are hosted on HuggingFace.\n",
    "- The benefit of using [FAISS vector store](https://python.langchain.com/docs/integrations/vectorstores/faiss)  is that it can use GPU for constructing embeddings which is faster that many other Vector Stores. It also stores the embeddings in local directory to be used by the models locally.\n",
    "\n",
    "**Note:**\n",
    "The LangChain integration portal currently has [53 VectorStores](https://integrations.langchain.com/vectorstores) and [39 Embedding Models](https://integrations.langchain.com/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452c14ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:29:55.579061500Z",
     "start_time": "2023-09-08T06:29:55.510375900Z"
    }
   },
   "outputs": [],
   "source": [
    "def _create_new_vectorstore(pdfs_path: str, split_chunk_size: int, split_overlap: int, \n",
    "                            embeddings_model_repo: str, embeddings_path: str):\n",
    "    \n",
    "    \"\"\" Creates a new vectorstore and embeddings model. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pdfs_path : str\n",
    "        Path to the directory containing PDF documents.\n",
    "    split_chunk_size : int\n",
    "        Size of the chunks to be created from the documents.\n",
    "    split_overlap : int\n",
    "        Overlap between two chunks.\n",
    "    embeddings_model_repo : str\n",
    "        Name of the embedding model to be used.\n",
    "    embeddings_path : str\n",
    "        Path to the directory where the vectorstore is to be stored.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vectorstore : langchain.vectorstores.faiss.FAISS\n",
    "        Vectorstore containing the embeddings of the documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # load PDF documents\n",
    "    documents = get_raw_pdf(pdfs_path)\n",
    "    \n",
    "    # split them into chunks\n",
    "    doc_chunks = get_document_chunks(documents, split_chunk_size, split_overlap)\n",
    "    \n",
    "    # create an embedding model\n",
    "    model_embeddings = HuggingFaceInstructEmbeddings(model_name = embeddings_model_repo,\n",
    "                                                     model_kwargs = {\"device\": \"cuda\"})\n",
    "\n",
    "    # create new_vectorstore\n",
    "    vec_store = FAISS.from_documents(documents = doc_chunks,\n",
    "                                     embedding = model_embeddings)\n",
    "\n",
    "    # persist vector database\n",
    "    vec_store.save_local(embeddings_path)\n",
    "    \n",
    "    return vec_store, model_embeddings\n",
    "\n",
    "def _load_prev_vectorstore(embeddings_model_repo: str, embeddings_path: str):\n",
    "    \n",
    "    \"\"\" Loads a previously created vectorstore and embeddings model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings_model_repo : str\n",
    "        Name of the embedding model to be used.\n",
    "    embeddings_path : str\n",
    "        Path to the directory where the vectorstore is to be stored.\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    vectorstore : langchain.vectorstores.faiss.FAISS\n",
    "        Vectorstore containing the embeddings of the documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # download embeddings model\n",
    "    model_embeddings = HuggingFaceInstructEmbeddings(model_name = embeddings_model_repo,\n",
    "                                                     model_kwargs = {\"device\": \"cuda\"})\n",
    "\n",
    "    # load vectorstore and embeddings\n",
    "    vec_store = FAISS.load_local(embeddings_path, model_embeddings)\n",
    "    \n",
    "    return vec_store, model_embeddings\n",
    "\n",
    "\n",
    "def create_vectorstore_embeddings(pdfs_path: str, split_chunk_size: int, split_overlap: int, \n",
    "                                  embeddings_model_repo: str, embeddings_path: str,\n",
    "                                  new_vectorstore: bool=False):\n",
    "    \n",
    "    \"\"\" Creates a new vectorstore and embeddings model if new_vectorstore is True else loads a previously created vectorstore and embeddings model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pdfs_path : str\n",
    "        Path to the directory containing PDF documents.\n",
    "    split_chunk_size : int\n",
    "        Size of the chunks to be created from the documents.\n",
    "    split_overlap : int\n",
    "        Overlap between two chunks.\n",
    "    embeddings_model_repo : str\n",
    "        Name of the embedding model to be used.\n",
    "    embeddings_path : str\n",
    "        Path to the directory where the vectorstore is to be stored.\n",
    "    new_vectorstore : bool\n",
    "        If True, creates a new vectorstore and embeddings model else loads a previously created vectorstore and embeddings model.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vectorstore : langchain.vectorstores.faiss.FAISS\n",
    "        Vectorstore containing the embeddings of the documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not new_vectorstore:\n",
    "        if os.path.isfile(embeddings_path+'/index.faiss'):\n",
    "            vec_store, model_embeddings = _load_prev_vectorstore(embeddings_model_repo, embeddings_path)\n",
    "            \n",
    "        else:\n",
    "            vec_store, model_embeddings = _create_new_vectorstore(pdfs_path, split_chunk_size, split_overlap, embeddings_model_repo, embeddings_path)\n",
    "    \n",
    "    else:\n",
    "        vec_store, model_embeddings = _create_new_vectorstore(pdfs_path, split_chunk_size, split_overlap, embeddings_model_repo, embeddings_path)\n",
    "     \n",
    "        \n",
    "    return vec_store, model_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a4f9bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:35:17.976116300Z",
     "start_time": "2023-09-08T06:29:58.580479800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:34<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "vectorstore, embeddings = create_vectorstore_embeddings(CFG.pdfs_path,\n",
    "                                                        CFG.split_chunk_size,\n",
    "                                                        CFG.split_overlap,\n",
    "                                                        CFG.embeddings_model_repo,\n",
    "                                                        CFG.embeddings_path,\n",
    "                                                        CFG.new_vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788ad12",
   "metadata": {},
   "source": [
    "### Step 4. Retrieve\n",
    "- A retriever is an interface that returns documents given an unstructured query. Vector Stores can be taken as retrievers to retrieve relevant documents.\n",
    "\n",
    "- Different types of retrieval methods include similarity search, Max marginal relevance, and similarity score threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4442d943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:35:18.018573200Z",
     "start_time": "2023-09-08T06:35:17.978769900Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs = {\"k\": CFG.k, \"search_type\" : CFG.search_type})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5c049",
   "metadata": {},
   "source": [
    "### Custom Prompt\n",
    "\n",
    "- Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. It is a part of tuning methodology for generating better outputs from LLMs. .  \n",
    "- The context is extracted from the Retriever and passed into the `context` variable and the query or user question is passed into `question` variable and passed through `PromptTemplate` to create a custom prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "729b558d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T22:31:54.345533Z",
     "start_time": "2023-09-10T22:31:54.326510800Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_en = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Answer in the same language the question was asked.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt_template_es = \"\"\"Utilice las siguientes piezas de contexto para responder la pregunta al final.\n",
    "Si no sabe la respuesta, simplemente diga que no la sabe, no intente inventar una respuesta.\n",
    "Mantenga su respuesta lo mÃ¡s concisa posible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "if CFG.model_language =='English':\n",
    "    prompt_template =  prompt_template_en\n",
    "elif CFG.model_language == 'Spanish':\n",
    "    prompt_template = prompt_template_es\n",
    "else:\n",
    "    raise ValueError('Language can only be \"English\" or \"Spanish\"')\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d45e86",
   "metadata": {},
   "source": [
    "### Step 5: Generate\n",
    "Create a response from the collected documents using the LLM/Chat model.\n",
    "\n",
    "- The LangChain integration portal currently has [69 LLMs](https://integrations.langchain.com/llms) and [14 Chat Models](https://integrations.langchain.com/chat-models).\n",
    "- Conversation (Extension) is applied on `chatbotapp.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b82be555",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever, \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33c8293",
   "metadata": {},
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b83d66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_ans(user_query, model_answer, answer_dict):\n",
    "    \n",
    "    \"\"\" Compares the answers from different models and stores them in a dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user_query : str\n",
    "        Query or question asked by the user.    \n",
    "    model_answer : dict\n",
    "        Answer returned by the model.\n",
    "    answer_dict : dict\n",
    "        Dictionary to store the answers from different questions.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ans_dict : dict\n",
    "        Dictionary with answers from different questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if answer_dict is None:\n",
    "        answer_dict = {user_query: model_answer['result']}\n",
    "    else:\n",
    "        answer_dict = {**answer_dict, **{user_query: model_answer['result']}}\n",
    "    return answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95387266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hagrid's favorite animals are magical creatures.\n",
      "CPU times: user 1.11 s, sys: 398 ms, total: 1.51 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ans_dict = None\n",
    "\n",
    "query = \"Which are Hagrid's favorite animals?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52437187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Harry faces three challenges during the Triwizard Tournament: the first challenge is a swimming race, the second challenge is a diving competition, and the third challenge is a dragon-riding competition.\n",
      "CPU times: user 2.7 s, sys: 649 ms, total: 3.35 s\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Which challenges does Harry face during the Triwizard Tournament?\"\n",
    "\n",
    "ans = qa_chain(query)\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f3e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.\tUnfogging Solution: This potion is used to remove the effects of a \"fomorogue\" curse, which causes the victim to be unable to speak the truth. The potion is made by mixing the powdered leaves of the \"floccinous frog\" plant with a small amount of the \"unfogging draught\" made from the \"star-shaped fern\" and \"glimmerwater\" plants. The resulting potion is then drunk by the victim, restoring their ability to speak the truth.\n",
      "2.\tPolyjuice Potion: This potion is used to transform one person into another, allowing them to take on the appearance and voice of the target. The potion is made by mixing the powdered leaves of the \"sphinx mandrake\" plant with a small amount of the \"hair of the dragon\" and \"hair of the cat\" plants. The resulting potion is then drunk by the person who wants to transform into the target.\n",
      "3.\tAmortentia Potion: This potion is used to help a witch or wizard remember a particular scent, which can be used to trigger a memory or a feeling of love. The potion is made by mixing the powdered leaves of the \"love vine\" plant with a small amount of the \"honeybee\" and \"honeyduff\" plants. The resulting potion is then sprayed or splashed onto a piece of cloth or a handkerchief.\n",
      "4.\tVeritaserum: This potion is used to force a person to tell the truth, even if they are normally unable to do so. The potion is made by mixing the powdered leaves of the \"blessed basil\" plant with a small amount of the \"unicorn horn\" and \"dragon claw\" plants. The resulting potion is then drunk by the person who wants to make them tell the truth.\n",
      "5.\tAguamenti: This potion is used to create a jet of water from a fountain pen, which can be used to put out fires or to clean objects. The potion is made by mixing the powdered leaves of the \"water lily\" plant with a small amount of the \"mermaid's voice\" and \"seaweed\" plants. The resulting potion is then added to the inkwell of a fountain pen.\n",
      "CPU times: user 23.8 s, sys: 3.11 s, total: 26.9 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Give me 5 examples of cool potions and explain what they do\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80cbf8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bill, Charlie, Percy, Ron, and Ginny Weasley.\n",
      "CPU times: user 1.81 s, sys: 649 ms, total: 2.45 s\n",
      "Wall time: 2.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Name all seven Weasley children.\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b1f4d86",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "query = \"Moony, Wormtail, Padfoot, and Prongs are code names for which four characters?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5f4cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Harry plays as the Keeper on the Gryffindor Quidditch team.\n",
      "CPU times: user 1.8 s, sys: 694 ms, total: 2.49 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"What position does Harry play on the Gryffindor Quidditch team?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2595ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The three different types of balls used in Quidditch are the Quaffle, the Bludger, and the Golden Snitch.\n",
      "CPU times: user 2.18 s, sys: 743 ms, total: 2.92 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Name the three different types of balls used in Quidditch.\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3399953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Crookshanks\n",
      "CPU times: user 974 ms, sys: 452 ms, total: 1.43 s\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"What is Hermione's cat's name?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e4f50",
   "metadata": {},
   "source": [
    "#### Out of scope questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c58a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gandalf was a powerful wizard who helped the characters in the story. He was a friend of Bilbo Baggins and helped the dwarves in their quest to reclaim their treasure from the dragon Smaug. He also helped the characters defeat the dark lord Sauron and his armies.\n",
      "CPU times: user 3.36 s, sys: 667 ms, total: 4.02 s\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"What did Gandalf do in the story?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d055483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, Gandalf was not in the Harry Potter books.\n",
      "CPU times: user 891 ms, sys: 180 ms, total: 1.07 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Was Gandalf in the Harry Potter books?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6228eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ron is afraid of spiders.\n",
      "CPU times: user 978 ms, sys: 429 ms, total: 1.41 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Which insect is Ron afraid of?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4730642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dobby killed himself by hanging himself with a rope he made from his own socks.\n",
      "CPU times: user 1.75 s, sys: 521 ms, total: 2.27 s\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Who killed Dobby?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3330c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are seven players on a Quidditch team: three Chasers, two Beaters, a Keeper, and a Seeker.\n",
      "CPU times: user 2.26 s, sys: 783 ms, total: 3.04 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"How many players are on a Quidditch team?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "305c06b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 700 ways of committing a Quidditch foul.\n",
      "CPU times: user 1.81 s, sys: 689 ms, total: 2.5 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"How many possible Quidditch fouls are there?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e52f1c",
   "metadata": {},
   "source": [
    "#### Spanish language questions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42f05940",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "query = \"Â¿CuÃ¡l es la profesiÃ³n de los padres de Harry Potter?\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bb29bc2",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "query = \"Dame 5 ejemplos de pociones geniales y explica para quÃ© sirven.\"\n",
    "ans = qa_chain(query)\n",
    "\n",
    "ans_dict = compare_model_ans(query, ans, ans_dict)\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b95181",
   "metadata": {},
   "source": [
    "## Export CSV Results\n",
    "\n",
    "- Model results are extracted for 10 predefined questions and exported as CSV to `csv_path`.  \n",
    "- If an answer is empty, that signifies that CUDA ran out of memory for that particular questions because of excess tokens.\n",
    "- The best model is saved in \"./model_comparison/best_model/\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a5dc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting csv of result answers for model comparison\n",
    "def export_results_to_csv(answer_dict, csv_path, model_name, embeddings_model_repo, search_type, \n",
    "                          temp, top_p, r_penalty, chunk_size, overlap):\n",
    "    \n",
    "    \"\"\" Exports the answers from different models to a CSV file.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    answer_dict : dict\n",
    "        Dictionary with answers from different questions.\n",
    "    csv_path : str\n",
    "        Path to the directory where the CSV file is to be stored.\n",
    "    model_name : str\n",
    "        Name of the model used.\n",
    "    embeddings_model_repo : str\n",
    "        Name of the embedding model used.\n",
    "    search_type : str\n",
    "        Type of search used by the retriever.\n",
    "    temp : float\n",
    "        Temperature used by the LLM.\n",
    "    top_p : float\n",
    "        Top_p used by the LLM.\n",
    "    r_penalty : float\n",
    "        Repetition penalty used by the LLM.\n",
    "    chunk_size : int\n",
    "        Size of the chunks to be created from the documents.\n",
    "    overlap : int\n",
    "        Overlap between two chunks.\n",
    "    \"\"\"\n",
    "    \n",
    "    ans_df = pd.DataFrame.from_dict([answer_dict])\n",
    "\n",
    "    embeddings_model_repo = embeddings_model_repo.replace('/', '--')\n",
    "\n",
    "    ans_df.to_csv(csv_path\n",
    "                  + model_name + '_' \n",
    "                  + embeddings_model_repo + '_'\n",
    "                  + search_type + '_('\n",
    "                  + str(temp) + '_'\n",
    "                  + str(top_p) + '_'\n",
    "                  + str(r_penalty) + '_'\n",
    "                  + str(chunk_size) + '_'\n",
    "                  + str(overlap) + ')'\n",
    "                  + '.csv', index=False)\n",
    "    \n",
    "    print('Model results saved at '\n",
    "          + csv_path\n",
    "          + ' with the name '\n",
    "          + model_name + '_'\n",
    "          + embeddings_model_repo + '_'\n",
    "          + search_type + '_('\n",
    "          + str(temp) + '_'\n",
    "          + str(top_p) + '_'\n",
    "          + str(r_penalty) + '_'\n",
    "          + str(chunk_size) + '_'\n",
    "          + str(overlap) + ')'\n",
    "          + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71b18018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results saved at ./model_comparison/ with the name vicuna_sentence-transformers--all-MiniLM-L12-v2_similarity_(0.1_0.95_1_500_100).csv\n"
     ]
    }
   ],
   "source": [
    "export_results_to_csv(ans_dict,\n",
    "                      CFG.csv_path,\n",
    "                      CFG.model_name, \n",
    "                      CFG.embeddings_model_repo, \n",
    "                      CFG.search_type,\n",
    "                      CFG.temperature, \n",
    "                      CFG.top_p, \n",
    "                      CFG.repetition_penalty,\n",
    "                      CFG.split_chunk_size,\n",
    "                      CFG.split_overlap\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb945a5",
   "metadata": {},
   "source": [
    "## Model performance\n",
    "\n",
    "- Since the data does not have a ground truth, i.e. the questions are not open domain, LLM performance using Exact-Match accuracy (EM) and f1 score is not feasible ([reference](https://aclanthology.org/2023.acl-long.307.pdf)). \n",
    "- One way to overcome this is to label the data (here Harry Potter Books) with ground truth and analyse the results with [Semantic Answer Similarity (SAS)](https://arxiv.org/abs/2108.06130) which is an extensive process itself.\n",
    "- Another method is to rank the answers of different models using another standalone LLM model. This is the base of [AlpacaEval](https://github.com/tatsu-lab/alpaca_eval?ref=radekosmulski.com) and current model rankings are posted at [leaderboard](https://tatsu-lab.github.io/alpaca_eval/).\n",
    "- Currently, model performance is calculated by experts to differentiate the quality of answers on 10 pre-defined questions with different modalities like short questions, long questions, out of scope questions and different language questions. The best model which generates better responses and its parameters are exported to run in `chatbotapp.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5834ee5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T09:01:23.465181600Z",
     "start_time": "2023-09-08T09:01:23.342520100Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "results_path = './model_comparison/' \n",
    "\n",
    "result_files = glob.glob(os.path.join(results_path, \"*.csv\"))\n",
    "\n",
    "index_list = list()\n",
    "\n",
    "for i in result_files:\n",
    "    index_list.append(i.split('/')[2].split('.csv')[0])\n",
    "    \n",
    "results_pd = pd.concat((pd.read_csv(f) for f in result_files), ignore_index=False)\n",
    "results_pd['model_name'] = index_list\n",
    "results_pd = results_pd.set_index('model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24948919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Which are Hagrid's favorite animals?</th>\n",
       "      <th>Which challenges does Harry face during the Triwizard Tournament?</th>\n",
       "      <th>Give me 5 examples of cool potions and explain what they do</th>\n",
       "      <th>Name all seven Weasley children.</th>\n",
       "      <th>What position does Harry play on the Gryffindor Quidditch team?</th>\n",
       "      <th>Name the three different types of balls used in Quidditch.</th>\n",
       "      <th>What is Hermione's cat's name?</th>\n",
       "      <th>What did Gandalf do in the story?</th>\n",
       "      <th>Which insect is Ron afraid of?</th>\n",
       "      <th>Who killed Dobby?</th>\n",
       "      <th>How many players are on a Quidditch team?</th>\n",
       "      <th>How many possible Quidditch fouls are there?</th>\n",
       "      <th>Â¿CuÃ¡l es la profesiÃ³n de los padres de Harry Potter?</th>\n",
       "      <th>Moony, Wormtail, Padfoot, and Prongs are code names for which four characters?</th>\n",
       "      <th>Dame 5 ejemplos de pociones geniales y explica para quÃ© sirven.</th>\n",
       "      <th>Was Gandalf in the Harry Potter books?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>falcon_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1_500_0)</th>\n",
       "      <td>Dragons.</td>\n",
       "      <td>Harry faces many challenges during the Triwiz...</td>\n",
       "      <td>\\n1. Healing Potion: This potion restores the ...</td>\n",
       "      <td>\\nRon\\nHermione\\nGinny\\nFred\\nGeorge\\nLuna</td>\n",
       "      <td>Harry plays as a Keeper.</td>\n",
       "      <td>The Quaffle, the Bludger, and the Golden Snitch.</td>\n",
       "      <td>Crookshanks</td>\n",
       "      <td>Gandalf is a wizard who helps Frodo and Sam o...</td>\n",
       "      <td>Cockroach</td>\n",
       "      <td>Harry Potter</td>\n",
       "      <td>There are seven players on a Quidditch team.</td>\n",
       "      <td>There are 10 possible Quidditch fouls.</td>\n",
       "      <td>Los padres de Harry Potter son profesores de ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>falcon_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1_500_200)</th>\n",
       "      <td>Hippogriffs</td>\n",
       "      <td>Harry faces challenges during the Triwizard T...</td>\n",
       "      <td>\\n1. Polyjuice Potion: This potion allows the ...</td>\n",
       "      <td>\\nRon\\nHermione\\nGinny\\nFred\\nGeorge\\nCharlie</td>\n",
       "      <td>Harry plays as the Keeper.</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>Crookshanks</td>\n",
       "      <td>Gandalf was a wizard who helped the Fellowshi...</td>\n",
       "      <td>The giant centipede.</td>\n",
       "      <td>Harry Potter</td>\n",
       "      <td>There are seven players on a Quidditch team.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los padres de Harry Potter son profesores de ...</td>\n",
       "      <td>They are code names for the four friends of H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b_intfloat--multilingual-e5-large_similarity_(0.1_0.95_1.15_800_0)</th>\n",
       "      <td>Hagrid doesn't have a favorite animal.</td>\n",
       "      <td>During the Triwizard Tournament, Harry faces ...</td>\n",
       "      <td>Ah, excellent! *adjusts spectacles* Well, my ...</td>\n",
       "      <td>Fred, George, Ron, Charlies, Percy, Bill, and...</td>\n",
       "      <td>Seeker</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>In the story, Gandalf went to the rescue of F...</td>\n",
       "      <td>Ron is afraid of spiders.</td>\n",
       "      <td>Harry Potter</td>\n",
       "      <td>There are 7 players on a Quidditch team.</td>\n",
       "      <td>There are seven hundred ways of committing a ...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b_intfloat--multilingual-e5-large_similarity_(0.5_0.95_1.15_800_0)</th>\n",
       "      <td>\"Well, so they say... I'd like a dragon.\"</td>\n",
       "      <td>During the Triwizard Tournament, Harry faces ...</td>\n",
       "      <td>Ah, excellent! *adjusts spectacles* Well, my ...</td>\n",
       "      <td>Ron, Fred, George, Charlus (Charlie), Percy, ...</td>\n",
       "      <td>Harry plays the position of Seeker on the Gry...</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In the story, Gandalf went to the rescue of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los padres de Harry Potter son abogados.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nDame five examples of genius potions and exp...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1_500_100)</th>\n",
       "      <td>Hagrid's favorite animals are dragons.</td>\n",
       "      <td>Harry faces three challenges during the Triwi...</td>\n",
       "      <td>\\n\\n1. Polyjuice Potion: This potion allows th...</td>\n",
       "      <td>George, Fred, Ron, Ginny, Bill, Charlie, and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crookshanks</td>\n",
       "      <td>Gandalf is a wizard who helps the characters ...</td>\n",
       "      <td>Scabbers.</td>\n",
       "      <td>Snape killed Dobby.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los padres de Harry Potter son muggles, perso...</td>\n",
       "      <td>Moony, Wormtail, Padfoot, and Prongs are code...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1_600_100)</th>\n",
       "      <td>Hagrid's favorite animals are dragons.</td>\n",
       "      <td>Harry faces three challenges during the Triwi...</td>\n",
       "      <td>\\n\\n1. Polyjuice Potion: This potion allows th...</td>\n",
       "      <td>George, Fred, Ron, Ginny, Bill, Charlie, and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crookshanks</td>\n",
       "      <td>Gandalf is a wizard who helps the characters ...</td>\n",
       "      <td>Scabbers.</td>\n",
       "      <td>Snape killed Dobby.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los padres de Harry Potter son muggles, perso...</td>\n",
       "      <td>Moony, Wormtail, Padfoot, and Prongs are code...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1_800_0)</th>\n",
       "      <td>Hagrid's favorite animals are dragons.</td>\n",
       "      <td>Harry faces three challenges during the Triwi...</td>\n",
       "      <td>\\n\\n1. Polyjuice Potion: This potion allows th...</td>\n",
       "      <td>\\n\\n1. \\n2. \\n3. \\n4. \\n5. \\n6. \\n7.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quaffle, Bludger, and Golden Snitch.</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>Gandalf was a wizard who helped the character...</td>\n",
       "      <td>Ron is afraid of spiders.</td>\n",
       "      <td>Harry Potter killed Dobby.</td>\n",
       "      <td>Harry Potter and Colin Creevey.</td>\n",
       "      <td>There are seven hundred ways of committing a ...</td>\n",
       "      <td>Los padres de Harry Potter son muggles, perso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna_sentence-transformers--all-MiniLM-L12-v2_similarity_(0.1_0.95_1_500_100)</th>\n",
       "      <td>Hagrid's favorite animals are magical creatures.</td>\n",
       "      <td>Harry faces three challenges during the Triwi...</td>\n",
       "      <td>\\n\\n1.\\tUnfogging Solution: This potion is use...</td>\n",
       "      <td>Bill, Charlie, Percy, Ron, and Ginny Weasley.</td>\n",
       "      <td>Harry plays as the Keeper on the Gryffindor Q...</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>Crookshanks</td>\n",
       "      <td>Gandalf was a powerful wizard who helped the ...</td>\n",
       "      <td>Ron is afraid of spiders.</td>\n",
       "      <td>Dobby killed himself by hanging himself with ...</td>\n",
       "      <td>There are seven players on a Quidditch team: ...</td>\n",
       "      <td>There are 700 ways of committing a Quidditch ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No, Gandalf was not in the Harry Potter books.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1.15_800_0)</th>\n",
       "      <td>Dogs and dragons (according to him).</td>\n",
       "      <td>The challenges that Harry faces during the Tr...</td>\n",
       "      <td>I apologize, but as an AI assistant, I am not ...</td>\n",
       "      <td>George, Fred, Ron, Ginny, Arthur, Molly, and B...</td>\n",
       "      <td>Harry plays the position of Seeker on the Gry...</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>I'm sorry, but there is no mention of a cat o...</td>\n",
       "      <td>In the story, Gandalf used his knowledge and ...</td>\n",
       "      <td>I'm sorry, but I cannot provide an accurate a...</td>\n",
       "      <td>I'm sorry, but I cannot provide an accurate a...</td>\n",
       "      <td>In the game of Quidditch, each team consists ...</td>\n",
       "      <td>There are seven hundred ways of committing a ...</td>\n",
       "      <td>I'm sorry, but I cannot provide an accurate a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1.25_800_0)</th>\n",
       "      <td>Dogs and dragons (according to him).</td>\n",
       "      <td>The challenges that Harry faces during the Tr...</td>\n",
       "      <td>I apologize for any confusion but it seems lik...</td>\n",
       "      <td>George, Fred, Ron, Arthur, Molly, Bill, Charlie.</td>\n",
       "      <td>Harry plays the position of Seeker on the Gry...</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>I am sorry, but there is no mention of a cat ...</td>\n",
       "      <td>In J. R. R. Tolkien's The Lord of the Rings, ...</td>\n",
       "      <td>I am sorry, but there is no information given...</td>\n",
       "      <td>I am sorry, but as an AI assistant, I do not ...</td>\n",
       "      <td>In the game of Quidditch, each team consists ...</td>\n",
       "      <td>There are seven hundred ways of committing a ...</td>\n",
       "      <td>I'm sorry, but there is no mention of any par...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1.5_800_0)</th>\n",
       "      <td>Dogs and dragons (according to him).</td>\n",
       "      <td>The Third Task which involves navigating thro...</td>\n",
       "      <td>I apologize for any confusion but it seems lik...</td>\n",
       "      <td>George Edward Ronald Brian Charlie Nicolas Bill</td>\n",
       "      <td>As mentioned earlier, Harry plays the positio...</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>I am sorry but there seems to have been a mis...</td>\n",
       "      <td>In J. R. Tolkien's The Lord of the Rings tril...</td>\n",
       "      <td>I am sorry but there seems to have been a mis...</td>\n",
       "      <td>I am sorry but there isn't enough information...</td>\n",
       "      <td>In standard play, seven players from each sid...</td>\n",
       "      <td>There are seven hundred ways of committing a ...</td>\n",
       "      <td>I am sorry; without additional information or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm_intfloat--multilingual-e5-large_similarity_(0.1_0.95_1.15_800_0)</th>\n",
       "      <td>Dogs and dragons (according to him).</td>\n",
       "      <td>The challenges that Harry faces during the Tr...</td>\n",
       "      <td>I apologize, but as an AI assistant, I am not ...</td>\n",
       "      <td>George, Fred, Ron, Ginny, Arthur, Molly, and B...</td>\n",
       "      <td>Harry plays the position of Seeker on the Gry...</td>\n",
       "      <td>The three different types of balls used in Qu...</td>\n",
       "      <td>I'm sorry, but there is no mention of a cat o...</td>\n",
       "      <td>In the story, Gandalf used his knowledge and ...</td>\n",
       "      <td>I'm sorry, but I cannot provide an accurate a...</td>\n",
       "      <td>I'm sorry, but I cannot provide an accurate a...</td>\n",
       "      <td>In the game of Quidditch, each team consists ...</td>\n",
       "      <td>There are seven hundred ways of committing a ...</td>\n",
       "      <td>I'm sorry, but I cannot provide an accurate a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Which are Hagrid's favorite animals?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                           Dragons.   \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                        Hippogriffs   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...             Hagrid doesn't have a favorite animal.   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...          \"Well, so they say... I'd like a dragon.\"   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...             Hagrid's favorite animals are dragons.   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...             Hagrid's favorite animals are dragons.   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...             Hagrid's favorite animals are dragons.   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   Hagrid's favorite animals are magical creatures.   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...               Dogs and dragons (according to him).   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...               Dogs and dragons (according to him).   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...               Dogs and dragons (according to him).   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...               Dogs and dragons (according to him).   \n",
       "\n",
       "                                                   Which challenges does Harry face during the Triwizard Tournament?  \\\n",
       "model_name                                                                                                             \n",
       "falcon_intfloat--multilingual-e5-large_similari...   Harry faces many challenges during the Triwiz...                  \n",
       "falcon_intfloat--multilingual-e5-large_similari...   Harry faces challenges during the Triwizard T...                  \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   During the Triwizard Tournament, Harry faces ...                  \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   During the Triwizard Tournament, Harry faces ...                  \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Harry faces three challenges during the Triwi...                  \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Harry faces three challenges during the Triwi...                  \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Harry faces three challenges during the Triwi...                  \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   Harry faces three challenges during the Triwi...                  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The challenges that Harry faces during the Tr...                  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The challenges that Harry faces during the Tr...                  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The Third Task which involves navigating thro...                  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The challenges that Harry faces during the Tr...                  \n",
       "\n",
       "                                                   Give me 5 examples of cool potions and explain what they do  \\\n",
       "model_name                                                                                                       \n",
       "falcon_intfloat--multilingual-e5-large_similari...  \\n1. Healing Potion: This potion restores the ...            \n",
       "falcon_intfloat--multilingual-e5-large_similari...  \\n1. Polyjuice Potion: This potion allows the ...            \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   Ah, excellent! *adjusts spectacles* Well, my ...            \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   Ah, excellent! *adjusts spectacles* Well, my ...            \n",
       "vicuna_intfloat--multilingual-e5-large_similari...  \\n\\n1. Polyjuice Potion: This potion allows th...            \n",
       "vicuna_intfloat--multilingual-e5-large_similari...  \\n\\n1. Polyjuice Potion: This potion allows th...            \n",
       "vicuna_intfloat--multilingual-e5-large_similari...  \\n\\n1. Polyjuice Potion: This potion allows th...            \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...  \\n\\n1.\\tUnfogging Solution: This potion is use...            \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...  I apologize, but as an AI assistant, I am not ...            \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...  I apologize for any confusion but it seems lik...            \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...  I apologize for any confusion but it seems lik...            \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...  I apologize, but as an AI assistant, I am not ...            \n",
       "\n",
       "                                                                     Name all seven Weasley children.  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...         \\nRon\\nHermione\\nGinny\\nFred\\nGeorge\\nLuna   \n",
       "falcon_intfloat--multilingual-e5-large_similari...      \\nRon\\nHermione\\nGinny\\nFred\\nGeorge\\nCharlie   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   Fred, George, Ron, Charlies, Percy, Bill, and...   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   Ron, Fred, George, Charlus (Charlie), Percy, ...   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   George, Fred, Ron, Ginny, Bill, Charlie, and ...   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   George, Fred, Ron, Ginny, Bill, Charlie, and ...   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...               \\n\\n1. \\n2. \\n3. \\n4. \\n5. \\n6. \\n7.   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...      Bill, Charlie, Percy, Ron, and Ginny Weasley.   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...  George, Fred, Ron, Ginny, Arthur, Molly, and B...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   George, Fred, Ron, Arthur, Molly, Bill, Charlie.   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...    George Edward Ronald Brian Charlie Nicolas Bill   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...  George, Fred, Ron, Ginny, Arthur, Molly, and B...   \n",
       "\n",
       "                                                   What position does Harry play on the Gryffindor Quidditch team?  \\\n",
       "model_name                                                                                                           \n",
       "falcon_intfloat--multilingual-e5-large_similari...                           Harry plays as a Keeper.                \n",
       "falcon_intfloat--multilingual-e5-large_similari...                         Harry plays as the Keeper.                \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                             Seeker                \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   Harry plays the position of Seeker on the Gry...                \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   Harry plays as the Keeper on the Gryffindor Q...                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   Harry plays the position of Seeker on the Gry...                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   Harry plays the position of Seeker on the Gry...                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   As mentioned earlier, Harry plays the positio...                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   Harry plays the position of Seeker on the Gry...                \n",
       "\n",
       "                                                   Name the three different types of balls used in Quidditch.  \\\n",
       "model_name                                                                                                      \n",
       "falcon_intfloat--multilingual-e5-large_similari...   The Quaffle, the Bludger, and the Golden Snitch.           \n",
       "falcon_intfloat--multilingual-e5-large_similari...   The three different types of balls used in Qu...           \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   The three different types of balls used in Qu...           \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   The three different types of balls used in Qu...           \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN           \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN           \n",
       "vicuna_intfloat--multilingual-e5-large_similari...               Quaffle, Bludger, and Golden Snitch.           \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   The three different types of balls used in Qu...           \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The three different types of balls used in Qu...           \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The three different types of balls used in Qu...           \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The three different types of balls used in Qu...           \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   The three different types of balls used in Qu...           \n",
       "\n",
       "                                                                       What is Hermione's cat's name?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                        Crookshanks   \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                        Crookshanks   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                              Snowy   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                        Crookshanks   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                        Crookshanks   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                      I don't know.   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...                                        Crookshanks   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but there is no mention of a cat o...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry, but there is no mention of a cat ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry but there seems to have been a mis...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but there is no mention of a cat o...   \n",
       "\n",
       "                                                                    What did Gandalf do in the story?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...   Gandalf is a wizard who helps Frodo and Sam o...   \n",
       "falcon_intfloat--multilingual-e5-large_similari...   Gandalf was a wizard who helped the Fellowshi...   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   In the story, Gandalf went to the rescue of F...   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   In the story, Gandalf went to the rescue of t...   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Gandalf is a wizard who helps the characters ...   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Gandalf is a wizard who helps the characters ...   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Gandalf was a wizard who helped the character...   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   Gandalf was a powerful wizard who helped the ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In the story, Gandalf used his knowledge and ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In J. R. R. Tolkien's The Lord of the Rings, ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In J. R. Tolkien's The Lord of the Rings tril...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In the story, Gandalf used his knowledge and ...   \n",
       "\n",
       "                                                                       Which insect is Ron afraid of?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                          Cockroach   \n",
       "falcon_intfloat--multilingual-e5-large_similari...                               The giant centipede.   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                          Ron is afraid of spiders.   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                          Scabbers.   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                          Scabbers.   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                          Ron is afraid of spiders.   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...                          Ron is afraid of spiders.   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but I cannot provide an accurate a...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry, but there is no information given...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry but there seems to have been a mis...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but I cannot provide an accurate a...   \n",
       "\n",
       "                                                                                    Who killed Dobby?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                       Harry Potter   \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                       Harry Potter   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                       Harry Potter   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                Snape killed Dobby.   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                Snape killed Dobby.   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                         Harry Potter killed Dobby.   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   Dobby killed himself by hanging himself with ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but I cannot provide an accurate a...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry, but as an AI assistant, I do not ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry but there isn't enough information...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but I cannot provide an accurate a...   \n",
       "\n",
       "                                                            How many players are on a Quidditch team?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...       There are seven players on a Quidditch team.   \n",
       "falcon_intfloat--multilingual-e5-large_similari...       There are seven players on a Quidditch team.   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...           There are 7 players on a Quidditch team.   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                    Harry Potter and Colin Creevey.   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   There are seven players on a Quidditch team: ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In the game of Quidditch, each team consists ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In the game of Quidditch, each team consists ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In standard play, seven players from each sid...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   In the game of Quidditch, each team consists ...   \n",
       "\n",
       "                                                         How many possible Quidditch fouls are there?  \\\n",
       "model_name                                                                                              \n",
       "falcon_intfloat--multilingual-e5-large_similari...             There are 10 possible Quidditch fouls.   \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                                NaN   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...   There are seven hundred ways of committing a ...   \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN   \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   There are seven hundred ways of committing a ...   \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   There are 700 ways of committing a Quidditch ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   There are seven hundred ways of committing a ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   There are seven hundred ways of committing a ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   There are seven hundred ways of committing a ...   \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   There are seven hundred ways of committing a ...   \n",
       "\n",
       "                                                   Â¿CuÃ¡l es la profesiÃ³n de los padres de Harry Potter?  \\\n",
       "model_name                                                                                                \n",
       "falcon_intfloat--multilingual-e5-large_similari...   Los padres de Harry Potter son profesores de ...     \n",
       "falcon_intfloat--multilingual-e5-large_similari...   Los padres de Harry Potter son profesores de ...     \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                      I don't know.     \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...           Los padres de Harry Potter son abogados.     \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Los padres de Harry Potter son muggles, perso...     \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Los padres de Harry Potter son muggles, perso...     \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Los padres de Harry Potter son muggles, perso...     \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...                                                NaN     \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but I cannot provide an accurate a...     \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but there is no mention of any par...     \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I am sorry; without additional information or...     \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...   I'm sorry, but I cannot provide an accurate a...     \n",
       "\n",
       "                                                   Moony, Wormtail, Padfoot, and Prongs are code names for which four characters?  \\\n",
       "model_name                                                                                                                          \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                                NaN                               \n",
       "falcon_intfloat--multilingual-e5-large_similari...   They are code names for the four friends of H...                               \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN                               \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN                               \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Moony, Wormtail, Padfoot, and Prongs are code...                               \n",
       "vicuna_intfloat--multilingual-e5-large_similari...   Moony, Wormtail, Padfoot, and Prongs are code...                               \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                               \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...                                                NaN                               \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                               \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                               \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                               \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                               \n",
       "\n",
       "                                                   Dame 5 ejemplos de pociones geniales y explica para quÃ© sirven.  \\\n",
       "model_name                                                                                                           \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                                NaN                \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...  \\nDame five examples of genius potions and exp...                \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                                NaN                \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...                                                NaN                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                                NaN                \n",
       "\n",
       "                                                             Was Gandalf in the Harry Potter books?  \n",
       "model_name                                                                                           \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                              NaN  \n",
       "falcon_intfloat--multilingual-e5-large_similari...                                              NaN  \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                              NaN  \n",
       "llama2-7b_intfloat--multilingual-e5-large_simil...                                              NaN  \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                              NaN  \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                              NaN  \n",
       "vicuna_intfloat--multilingual-e5-large_similari...                                              NaN  \n",
       "vicuna_sentence-transformers--all-MiniLM-L12-v2...   No, Gandalf was not in the Harry Potter books.  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                              NaN  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                              NaN  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                              NaN  \n",
       "wizardlm_intfloat--multilingual-e5-large_simila...                                              NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41736ec2",
   "metadata": {},
   "source": [
    "results_pd[\"Which are Hagrid's favorite animals?\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bc5a9c8",
   "metadata": {},
   "source": [
    "results_pd[\"Which challenges does Harry face during the Triwizard Tournament?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e18cbe",
   "metadata": {},
   "source": [
    "#### Insert best model according to your judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a2af3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"vicuna_intfloat--multilingual-e5-large_similarity_(0.0_0.95_1_500_100)\"\n",
    "# best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc7dbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to export excel file to best_model folder for reference\n",
    "# import shutil\n",
    "# original = './model_comparison/' + best_model + '.csv'\n",
    "# target = './model_comparison/best_model/' + best_model + '.csv'\n",
    "# shutil.copyfile(original, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106c11a",
   "metadata": {},
   "source": [
    "#### Best model parameters export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8de96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name\n",
    "bm_name = best_model.split('_')[0]\n",
    "\n",
    "# model repository\n",
    "bm_repo = available_models[bm_name]\n",
    "\n",
    "# embedding model\n",
    "try:\n",
    "    bm_embedder = best_model.split('_')[1].replace('--', '/')\n",
    "except:\n",
    "    bm_embedder = best_model.split('_')[1]\n",
    "    \n",
    "# search_type  \n",
    "bm_search_type = best_model.split('_')[2]\n",
    "\n",
    "# model temperature\n",
    "try:\n",
    "    bm_temp = best_model.split('_')[3].split('(')[1]\n",
    "except:\n",
    "    bm_temp = best_model.split('_')[3]\n",
    "    \n",
    "# model top_p\n",
    "bm_top_p = best_model.split('_')[4]\n",
    "\n",
    "# repetition penalty\n",
    "bm_rep_penalty = best_model.split('_')[5]\n",
    "\n",
    "# model split chunks\n",
    "bm_split_chunks = best_model.split('_')[6]\n",
    "\n",
    "# model split overlap\n",
    "try:\n",
    "    bm_split_overlap = best_model.split('_')[7].split(')')[0]\n",
    "except:\n",
    "    bm_split_overlap = best_model.split('_')[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "555f1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [bm_name, bm_repo, bm_embedder, bm_search_type, bm_temp, bm_top_p, bm_rep_penalty, bm_split_chunks, bm_split_overlap]\n",
    "file = open('./model_comparison/best_model/best-model-parameters.txt','w')\n",
    "for i in param:\n",
    "    file.write(i+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131d9a9",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "There are many improvements that can be made with better resources and time as well as manipulating the following parameters:\n",
    "- Model hyperparameters like temperature, top_p, repetition_penalty, max_length, etc.\n",
    "- Different embeddings models\n",
    "- Retriever hyperparameters like similarity, MMR, similarity threshold, k or different retrievers like SVMRetriever\n",
    "- Bigger models with higher performance\n",
    "- Custom prompt engineering\n",
    "- Other types of models can be implemented to improve the performance, current models were taken from `HuggingFaceHub` and are working well\n",
    "- Splitting: chunk size, overlap can be manipulated to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba8843",
   "metadata": {},
   "source": [
    "### Use cases\n",
    "- Other types of PDFs can be imported to parse through for QA\n",
    "- More languages can be added by either adding a separate LLM chain to translate, using multilingual embedding models and retrievers or using a different LLM model which supports multiple languages. Fine-tuning models is also possible on different language datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1e24f57b8672d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
